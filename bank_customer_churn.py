# -*- coding: utf-8 -*-
"""Bank customer churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fMCy0Z6U9DIB2iPqeU7esZEcwj8SUMYj
"""

import pandas as pd

data = pd.read_csv("Churn_Modelling.csv")

#Display top 5 rows of the dataset
data.head()

#Display last 5 rows of the dataset
data.tail()

#shape of our dataset (number of rows and columns)
data.shape

print("Number of Rows", data.shape[0])
print("Number of Columns", data.shape[1])

#Information about our dataset like total number rows , total number of columns ,Data types of each column and memory requirement
data.info()

#check null values in the dataset
data.isnull().sum()

#overall statistics about the dataset
data.describe(include='all')

#Dropping irrelevant features
data.columns

data =  data.drop(['RowNumber','CustomerId','Surname'],axis=1)
data.head()

#encoding categorical data
data['Geography'].unique()

data =pd.get_dummies(data,drop_first =True)
data.head()

#Not Handling Imbalanced
data['Exited'].value_counts()

import seaborn as sns

sns.countplot(data["Exited"])

x = data.drop("Exited",axis = 1)
y = data['Exited']

y

#Handling the imbalanced Data with SMOTE
from imblearn.over_sampling import SMOTE
x_res,y_res = SMOTE().fit_resample(x,y)

y_res.value_counts()

#splitting the dataset into the training set and test set
from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x_res,y_res,test_size=0.20,random_state=42)

#Feature scaling
from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

#Logistic Regression
from sklearn.linear_model import LogisticRegression

log = LogisticRegression()
log.fit(x_train, y_train)

y_pred1 = log.predict(x_test)

from sklearn.metrics import accuracy_score

accuracy_score(y_test,y_pred1)

accuracy_score(y_test,y_pred1)

from sklearn.metrics import precision_score, recall_score,f1_score

precision_score(y_test,y_pred1)

precision_score(y_test,y_pred1)

recall_score(y_test, y_pred1)

f1_score(y_test,y_pred1)

f1_score(y_test,y_pred1)

pc = TF / (FP+TP)

#SVC
from sklearn import svm
svm = svm.SVC()
svm.fit(x_train,y_train)

y_pred2 = svm.predict(x_test)
accuracy_score(y_test,y_pred2)

precision_score(y_test,y_pred2)

#Kneighbors Classifier
from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(x_train,y_train)

y_pred3 = knn.predict(x_test)
accuracy_score(y_test,y_pred3)

precision_score(y_test,y_pred3)

#Decision Tree Classifier
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(x_train,y_train)

y_pred4 = dt.predict(x_test)
accuracy_score(y_test,y_pred4)

precision_score(y_test,y_pred4)

#Random Forest Classifier
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier()
rf.fit(x_train,y_train)
y_pred5 = rf.predict(x_test)
accuracy_score(y_test,y_pred5)

precision_score(y_test,y_pred5)

#Gradient Boosting Classsifier
from sklearn.ensemble import GradientBoostingClassifier
gbc = GradientBoostingClassifier()
gbc.fit(x_train,y_train)

y_pred6 = gbc.predict(x_test)
accuracy_score(y_test,y_pred6)

precision_score(y_test,y_pred6)

final_data = pd.DataFrame({'Models':['LR','SVC','KNN','DT','RF','GBC'],'ACC':[accuracy_score(y_test,y_pred1),
                                                                              accuracy_score(y_test,y_pred2),
                                                                              accuracy_score(y_test,y_pred3),
                                                                              accuracy_score(y_test,y_pred4),
                                                                              accuracy_score(y_test,y_pred5),
                                                                              accuracy_score(y_test,y_pred6)]})

final_data

import seaborn as sns

sns.barplot(x=final_data['Models'] , y=final_data['ACC'])

final_data = pd.DataFrame({'Models':['LR','SVC','KNN','DT','RF','GBC'],'PRE':[precision_score(y_test,y_pred1),
                                                                              precision_score(y_test,y_pred2),
                                                                              precision_score(y_test,y_pred3),
                                                                              precision_score(y_test,y_pred4),
                                                                              precision_score(y_test,y_pred5),
                                                                              precision_score(y_test,y_pred6)]})

final_data

import seaborn as sns
sns.barplot(x=final_data['Models'] , y=final_data['PRE'])

#save the Model
x_res = sc.fit_transform(x_res)
rf.fit(x_res,y_res)

import joblib
joblib.dump(rf,'churn_predict_model')

model = joblib.load('churn_predict_model')

data.columns

model.predict([[619,42,2,0.0,0,0,0,101348.88,0,0,0]])

